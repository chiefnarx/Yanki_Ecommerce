# ğŸ›’ Yanki Ecommerce Data Pipeline

Yanki Ecommerce is a data engineering project designed to extract, clean, and normalize transactional retail data for a fictional ecommerce platform. Starting with a raw CSV dataset, the project transforms it into structured relational tables and loads them into a PostgreSQL database using Python. The final schema supports queries for customer behavior, product insights, and payment tracking.

---

## ğŸ“Œ Project Overview

This project builds a clean and normalized ecommerce database pipeline from scratch, covering:

âœ… Extract raw ecommerce data from CSV  
âœ… Clean and transform key entities using pandas  
âœ… Split dataset into individual logical tables  
âœ… Create PostgreSQL schema and insert transformed data  

---

## âš™ï¸ Technologies Used

 âº Python (`pandas`, `csv`, `psycopg2`) â€” ETL and ingestion  
 âº PostgreSQL â€” relational database setup  
 âº SQL (`DDL`, `DML`) â€” schema design and inserts  

---

## ğŸ”„ Full ETL Workflow

### 1. Data Extraction and Cleaning

- Read raw CSV file containing transaction data  
- Dropped incomplete records based on key columns  
- Converted `Order_Date` to datetime format  
- Extracted unique entities from the dataset:
  - `customers`
  - `products`
  - `shipping_address`
  - `orders`
  - `payment_method`  

- Saved each cleaned entity into a separate CSV for staging

### 2. PostgreSQL Schema Creation

- Created schema `yanki` using SQL DDL  
- Defined tables:
  - `customers`  
  - `products`  
  - `shipping_address`  
  - `orders`  
  - `payment_method`  

- Enforced data types, primary keys, and foreign key relationships across tables

### 3. Data Loading into PostgreSQL

- Wrote Python functions to load each CSV into its respective PostgreSQL table  
- Used `INSERT INTO` statements with placeholders via `psycopg2` 
- Handled primary key constraints and maintained referential integrity  
- Executed inserts efficiently and committed transaction batches  

---

## ğŸ“„ Results & Final Verification

âœ… Cleaned and normalized retail dataset  
âœ… Five well-structured relational tables created  
âœ… PostgreSQL database successfully loaded  
âœ… Queries supported for customer activity, order tracking, and payment analysis  

---

## ğŸ“ Notes

 âº Used UUIDs for unique identity columns across customers, products, and orders  
 âº Applied pandas transformations to enforce clean schema formats  
 âº Created reusable ingestion logic with conflict handling and modular inserts  
 âº Database designed for future scaling with additional ecommerce metrics  
